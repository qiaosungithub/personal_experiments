{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718d6fe6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b66c03c90ce725319f0691dfb29845ac",
     "grade": false,
     "grade_id": "cell-9c430af5d8d383e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Energy-Based Model, with Hamiltonian Monte Carlo Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a90a8be",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "629c76063b8cf64b9021654fbe717d41",
     "grade": false,
     "grade_id": "cell-527c7725f3508ba0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Tips\n",
    "\n",
    "+ Training with naive contrastive-divergence algorithm will make your model diverge quickly (think about why). Therefore, you need to add a L2 regularization term $\\alpha(E_\\theta(x+)^2 + E_\\theta(x-)^2)$ to stabilize training.\n",
    "\n",
    "+ Take a look at the paper [Implicit Generation and Generalization in Energy Based Models](https://arxiv.org/pdf/1903.08689.pdf) to learn more about useful tricks to get your model working."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd040c70",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54854fcdc1556d353b55bc4d1a133674",
     "grade": false,
     "grade_id": "cell-2b4bea3e44a7b81b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Set Up Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca3738",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0bb447e0084709f0b673b1e91ba0aa1a",
     "grade": false,
     "grade_id": "cell-291232b1c59e4f02",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you use Colab in this coding project, please uncomment the code, fill the `GOOGLE_DRIVE_PATH_AFTER_MYDRIVE` and run the following cells to mount your Google drive. Then, the notebook can find the required file (i.e., utils.py). If you run the notebook locally, you can skip the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c2354b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b34bc8b23f9c8e480a9671ef3453e7ac",
     "grade": false,
     "grade_id": "cell-a551fcc5ff27fb87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Sep 21 17:02:41 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000004:04:00.0 Off |                    0 |\n",
      "| N/A   55C    P0              71W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "/nobackup/users/sqa24/anaconda3/envs/wgt/bin/python\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib widget\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "!nvidia-smi\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6cd2080",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d5d6f96e1d7ce5df1315172b57173de",
     "grade": false,
     "grade_id": "cell-e11eaf041d72deda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Good luck!\n"
     ]
    }
   ],
   "source": [
    "from ebm_hamiltonian.models.utils import hello\n",
    "hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bf1d5cb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc6d9d087b7f8aedc3401222f717bb07",
     "grade": false,
     "grade_id": "cell-c0b91f0d2b7ecc80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "from ebm_hamiltonian.models.utils import save_model, load_model, corruption, train_set, val_set\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "os.makedirs('./ebm', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b76802",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dbb5921ccbc0e1e14fd40df09afebcac",
     "grade": false,
     "grade_id": "cell-f28aaf301b501410",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Enenrgy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3ca4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebm_hamiltonian.models.resnet import ResNet_MNIST, CNN_MNIST, SNCNN_MNIST\n",
    "from ebm_hamiltonian.models.basicblock import BasicBlock\n",
    "\n",
    "# input size: 1x28x28\n",
    "\n",
    "def MLP(hidden_dim=None):\n",
    "    model = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(28*28, 1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(1024, 512), \n",
    "        nn.ReLU(),\n",
    "        # nn.Linear(512, 512), \n",
    "        # nn.ReLU(),\n",
    "        nn.Linear(512, 1)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def resnet34(hidden_dim=128):\n",
    "    \"\"\"Constructs a ResNet-34 model.\"\"\"\n",
    "    model = ResNet_MNIST(block=BasicBlock, \n",
    "                         hidden_dim=hidden_dim,\n",
    "                   layers=[5, 5, 5]\n",
    "                   )\n",
    "    return model\n",
    "\n",
    "def Swish(x):\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "def cnn(hidden_dim=128, activation=Swish):\n",
    "    model = CNN_MNIST(block=BasicBlock, hidden_dim=hidden_dim, activation=activation)\n",
    "    return model\n",
    "\n",
    "def sncnn(hidden_dim=128, activation=Swish):\n",
    "    model = SNCNN_MNIST(block=BasicBlock, hidden_dim=hidden_dim, activation=activation)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d61159f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd456d1555c954ff15d4cfcb44b144f5",
     "grade": false,
     "grade_id": "cell-cafb02a0cc941c58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Sampling\n",
    "\n",
    "Langevin dynamics. Pay attention to the gradients of both your energy model and input.\n",
    "\n",
    "Hamiltonian Monte Carlo. TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b704099a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91d2744d6a964f70ff2c85c161f92c9f",
     "grade": false,
     "grade_id": "cell-afd44e44fcd9d650",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_energy_grad(energy_model, x):\n",
    "    x = x.clone().detach()\n",
    "    x.requires_grad = True\n",
    "    energy_model.zero_grad()\n",
    "    energy = energy_model(x)\n",
    "    energy.sum().backward()\n",
    "    energy_model.zero_grad()\n",
    "    # print('x.grad:', x.grad.min(), x.grad.max())\n",
    "    return x.grad\n",
    "\n",
    "def langevin_step(energy_model, x, eps, step_lr, max_grad_norm=None):\n",
    "    \"\"\"\n",
    "    Perform one step of Langevin dynamics sampling.\n",
    "\n",
    "    Args:\n",
    "        energy_model (nn.Module): The energy-based model used for sampling.\n",
    "        x (torch.Tensor): The input tensor to update via Langevin dynamics.\n",
    "        step_lr (float): The step size of the optimizer used to update the input. \n",
    "        eps (float): noise level\n",
    "        max_grad_norm (float or None): The maximum norm of the gradient for gradient clipping.\n",
    "\n",
    "        x <- x + eps^2/2 * grad_x log p(x) + eps * N(0, I)\n",
    "            = x - eps^2/2 * grad_x E(x) + eps * N(0, I)\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The updated input tensor after one step of Langevin dynamics.\n",
    "    \"\"\"\n",
    "    gradient = get_energy_grad(energy_model, x)\n",
    "\n",
    "    noise = torch.randn_like(x) * (eps**0.5)\n",
    "\n",
    "    # if max_grad_norm is not None:\n",
    "    #     gradient = gradient.clamp(-max_grad_norm, max_grad_norm)\n",
    "    # gradient = gradient.reshape(x.shape[0],-1)\n",
    "\n",
    "    # if max_grad_norm is not None:\n",
    "    #     do_clip = gradient.norm(dim=-1,keepdim=True) > max_grad_norm\n",
    "    #     gradient = torch.where(do_clip, gradient / gradient.norm(dim=-1, keepdim=True) * max_grad_norm, gradient)\n",
    "    # gradient = gradient.reshape_as(x)\n",
    "    # print('gradient.range:', gradient.min(), gradient.max())\n",
    "\n",
    "    x_new = x - step_lr * gradient + noise\n",
    "    \n",
    "    x_new = torch.clamp(x_new, 0, 1)  # Ensure pixel values are between 0 and 1\n",
    "\n",
    "    return x_new\n",
    "\n",
    "def hamiltonian_step(energy_model, x, A, B, n_steps, max_grad_norm=None, reject=False, bound=True):\n",
    "    \"\"\"\n",
    "    Perform one step of Hamiltonian MCMC.\n",
    "\n",
    "    Args:\n",
    "        energy_model (nn.Module): The energy-based model used for sampling.\n",
    "        x (torch.Tensor): The input tensor to update via Langevin dynamics.\n",
    "        A: the magnitude of change of image per pixel\n",
    "        B: should be the same magnitude as the gradient of energy\n",
    "        eps (float): step size\n",
    "        p_norm: the initial momentum norm\n",
    "        n_steps (int): number of leapfrog steps before resampling p (or the L in the paper)\n",
    "        max_grad_norm (float or None): The maximum norm of the gradient for gradient clipping. (optional)\n",
    "        reject: if True, we may reject due to energy difference\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The updated input tensor after one step of Langevin dynamics.\n",
    "    \"\"\"\n",
    "    eps = sqrt(A/B)\n",
    "    p_norm = sqrt(A*B)\n",
    "    x_init = x.clone().detach()\n",
    "    gradient = get_energy_grad(energy_model, x)\n",
    "        \n",
    "    p = torch.randn_like(x) * p_norm\n",
    "    assert p.shape == torch.Size([x.shape[0], 1, 28, 28])\n",
    "\n",
    "    init_total_energy = energy_model(x).squeeze(1) + 0.5 * p.pow(2).sum(dim=(1, 2, 3))\n",
    "\n",
    "    p = p - 0.5 * eps * gradient\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        x = x + eps * p\n",
    "        if bound:\n",
    "            p = torch.where(x < 0, -p, p)\n",
    "            p = torch.where(x > 1, -p, p)\n",
    "            x = torch.where(x < 0, -x, x)\n",
    "            x = torch.where(x > 1, 2 - x, x)\n",
    "        x = torch.clamp(x, 0, 1)\n",
    "        if i != n_steps - 1:\n",
    "            gradient = get_energy_grad(energy_model, x)\n",
    "            p = p - eps * gradient\n",
    "        # print('x:',x[0,0,0,0])\n",
    "        # print('p:',p[0,0,0,0])\n",
    "\n",
    "    gradient = get_energy_grad(energy_model, x)\n",
    "    p = p - 0.5 * eps * gradient\n",
    "\n",
    "    current_energy = energy_model(x).squeeze(1) + 0.5 * p.pow(2).sum(dim=(1, 2, 3))\n",
    "\n",
    "    # print(\"total energy difference: \", (current_energy - init_total_energy).mean().item())\n",
    "    assert init_total_energy.shape == current_energy.shape and init_total_energy.shape == torch.Size([x.shape[0]])\n",
    "\n",
    "    # optional: decide whether to reject\n",
    "    if reject:\n",
    "        accept_prob = torch.exp(init_total_energy - current_energy)\n",
    "        accept = torch.rand(x.shape[0]).to(x.device) < accept_prob\n",
    "        x = torch.where(accept[:, None, None, None], x, x_init)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd80f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = cnn().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba5264a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# sqrt = math.sqrt\n",
    "# def test(use_hamiltonian=False):\n",
    "#     x = torch.rand(256, 1, 28, 28).to(device)\n",
    "#     # print(x)\n",
    "#     # model = MLP().to(device)\n",
    "#     print(\"energy: \", model(x).sum().item())\n",
    "#     if use_hamiltonian:\n",
    "#         A = 2e-2 # the change of x\n",
    "#         B = 2e-4 # the change of p / eps, which should be relative to the gradient\n",
    "#         print(\"using hamiltonian\")\n",
    "#         for i in range(5):\n",
    "#             x = hamiltonian_step(model, x, A=A, B=B, n_steps=10, max_grad_norm=0.03, reject=True)\n",
    "#             # print(x)\n",
    "#             print(\"energy:\" ,model(x).sum().item())\n",
    "#     else:\n",
    "#         print(\"using langevin\")\n",
    "#         for i in range(100):\n",
    "#             x = langevin_step(model, x, eps=0.01, step_lr=1e3, max_grad_norm=0.03)\n",
    "#             # print(x)\n",
    "#             print(\"energy:\" ,model(x).sum().item())\n",
    "\n",
    "# test(use_hamiltonian=1)\n",
    "# # eps * p_norm = A = 3e-2\n",
    "# # or: eps * grad (1e-2) = 5e-2\n",
    "# # p_norm = eps * B (B = 1e-2)\n",
    "# # eps = sqrt(A/B)\n",
    "# # p_norm = sqrt(A*B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae72a49",
   "metadata": {},
   "source": [
    "MLP: 结果差不多, HMC稍微好一点\n",
    "\n",
    "__langevin__: 0.2s, 60 steps, step_lr=10, eps=0.01, energy -> -210\n",
    "          0.3s, 100 steps, step_lr=10, eps=0.01, energy -> -205\n",
    "\n",
    "__hmc__: 0.0s, 1 group of 10 steps, eps = sqrt3, p_norm = sqrt(3e-4), energy -> -117\n",
    "\n",
    "0.3s, 10 groups of 10 steps, eps = sqrt3, p_norm = sqrt(3e-4), energy -> -230\n",
    "\n",
    "0.3s, 10 groups of 5 steps, eps = sqrt3, p_norm = sqrt(3e-4), energy -> -203\n",
    "     \n",
    "0.4s, 20 groups of 5 steps, eps = sqrt3, p_norm = sqrt(3e-4), energy -> -224\n",
    "\n",
    "resnet: 不太稳定\n",
    "\n",
    "cnn: \n",
    "\n",
    "__langevin__: 1.9s, 100 steps, step_lr=1000, eps=0.01, energy 12 -> 9\n",
    "\n",
    "__hmc__: 0.6s, 3 groups of 10 steps, A = 2e-2, B = 2e-4, energy 12 -> 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1fdbf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5171faedb56d4b5f97620596006e4525",
     "grade": false,
     "grade_id": "cell-508a10378fa57a85",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Inpainting\n",
    "\n",
    "Implement the inpainting procedure. Think about the difference between sampling and inpainting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7ed1856",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15d3e13b437efa0e295540e214b3a612",
     "grade": false,
     "grade_id": "cell-5fce3238f7ff50db",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def inpainting(energy_model, x, mask, n_steps, step_lr, max_grad_norm, eps=0.005, add_noise=True):\n",
    "    \"\"\"\n",
    "    Inpainting function that completes an image given a masked input using Langevin dynamics.\n",
    "\n",
    "    Args:\n",
    "        energy_model (nn.Module): The energy-based model used to generate the image.\n",
    "        x (torch.Tensor): The input tensor, a masked image that needs to be completed.\n",
    "        mask (torch.Tensor): The mask tensor, with the same shape as x, where 1 indicates the corresponding\n",
    "                             pixel is visible and 0 indicates it is missing.\n",
    "        n_steps (int): The number of steps of Langevin dynamics to run.\n",
    "        step_lr (float): The step size of Langevin dynamics.\n",
    "        max_grad_norm (float or None): The maximum gradient norm to be used for gradient clipping. If None, \n",
    "                                       no gradient clipping is performed.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The completed image tensor.\n",
    "    \"\"\"\n",
    "    reverse_mask = 1-mask\n",
    "\n",
    "\n",
    "    for _ in range(n_steps):\n",
    "        gradient = get_energy_grad(energy_model, x)\n",
    "        if max_grad_norm is not None:\n",
    "            gradient = gradient.clamp(-max_grad_norm, max_grad_norm)\n",
    "\n",
    "        add_noise = False\n",
    "        if add_noise:\n",
    "            noise = eps * torch.randn_like(x) * reverse_mask\n",
    "        else:\n",
    "            noise = 0\n",
    "        if _ == n_steps-1:\n",
    "            noise = 0\n",
    "\n",
    "        x = x - step_lr * gradient * reverse_mask + noise\n",
    "        x = torch.clamp(x, 0, 1)  # Ensure pixel values are between 0 and 1\n",
    "\n",
    "\n",
    "    return x\n",
    "\n",
    "def inpainting_hmc(energy_model, x, mask, n_steps_per_sample, n_samples, A, B, max_grad_norm, reject=False, bound=True):\n",
    "    \"\"\"\n",
    "    Inpainting function that completes an image given a masked input using MHC.\n",
    "\n",
    "    Args:\n",
    "        energy_model (nn.Module): The energy-based model used to generate the image.\n",
    "        x (torch.Tensor): The input tensor, a masked image that needs to be completed.\n",
    "        mask (torch.Tensor): The mask tensor, with the same shape as x, where 1 indicates the corresponding\n",
    "                             pixel is visible and 0 indicates it is missing.\n",
    "        n_steps_per_sample (int): The number of leapfrog steps to run for each sample.\n",
    "        n_samples (int): The number of samples of p to generate.\n",
    "        A & B: the same as in hamiltonian_step\n",
    "        max_grad_norm (float or None): The maximum gradient norm to be used for gradient clipping. If None, \n",
    "                                       no gradient clipping is performed.\n",
    "        reject: if True, we may reject due to energy difference\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The completed image tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    eps = sqrt(A/B)\n",
    "    p_norm = sqrt(A*B)\n",
    "\n",
    "    reverse_mask = 1-mask\n",
    "\n",
    "    current_energy = energy_model(x).squeeze(1)\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        x_init = x.clone().detach()\n",
    "        gradient = get_energy_grad(energy_model, x)\n",
    "            \n",
    "        p = torch.randn_like(x) * p_norm * reverse_mask # we only allow moving the pixels that are free\n",
    "        assert p.shape == torch.Size([x.shape[0], 1, 28, 28])\n",
    "\n",
    "        init_total_energy = current_energy + 0.5 * p.pow(2).sum(dim=(1, 2, 3))\n",
    "\n",
    "        p = p - 0.5 * eps * gradient * reverse_mask\n",
    "\n",
    "        for i in range(n_steps_per_sample):\n",
    "            x = x + eps * p * reverse_mask\n",
    "            if bound:\n",
    "                p = torch.where(x < 0, -p, p)\n",
    "                p = torch.where(x > 1, -p, p)\n",
    "                x = torch.where(x < 0, -x, x)\n",
    "                x = torch.where(x > 1, 2 - x, x)\n",
    "            x = torch.clamp(x, 0, 1)\n",
    "            if i != n_steps_per_sample - 1:\n",
    "                gradient = get_energy_grad(energy_model, x)\n",
    "                p = p - eps * gradient * reverse_mask\n",
    "            # print('x:',x[0,0,13,15])\n",
    "            # print('p:',p[0,0,13,15])\n",
    "\n",
    "        gradient = get_energy_grad(energy_model, x)\n",
    "        p = p - 0.5 * eps * gradient * reverse_mask\n",
    "\n",
    "        new_energy = energy_model(x).squeeze(1)\n",
    "        new_total_energy = new_energy + 0.5 * p.pow(2).sum(dim=(1, 2, 3))\n",
    "\n",
    "        # print(\"total energy difference: \", (new_total_energy - init_total_energy).mean().item())\n",
    "\n",
    "        # optional: decide whether to reject\n",
    "        if reject:\n",
    "            accept_prob = torch.exp(init_total_energy - new_total_energy)\n",
    "            accept = torch.rand(x.shape[0]).to(x.device) < accept_prob\n",
    "            x = torch.where(accept[:, None, None, None], x, x_init)\n",
    "            current_energy = torch.where(accept, new_energy, current_energy)\n",
    "        else:\n",
    "            current_energy = new_energy\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "593bd650",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6153ff029424a3266efd4b44329a1223",
     "grade": false,
     "grade_id": "cell-e4f7157f3a2421d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(energy_model, val_loader, use_hmc, sh, device=device):\n",
    "    \"\"\"\n",
    "    Evaluates the energy model on the validation set and returns the corruption MSE,\n",
    "    recovered MSE, corrupted images, and recovered images for visualization.\n",
    "\n",
    "    Args:\n",
    "        energy_model (nn.Module): Trained energy-based model.\n",
    "        val_loader (torch.utils.data.DataLoader): Validation data loader.\n",
    "        use_hmc (bool)\n",
    "        sh (sampling_hyperparamters): a dictionary of parameters, depending on whether to use hmc\n",
    "        langevin:\n",
    "            n_sample_steps (int): Number of Langevin dynamics steps to take when sampling.\n",
    "            step_lr (float): Learning rate to use during Langevin dynamics.\n",
    "            langevin_grad_norm (float): Maximum L2 norm of the Langevin dynamics gradient.\n",
    "            eps & add_noise\n",
    "        hmc:\n",
    "            n_steps_per_sample (int): Number of leapfrog steps to run for each sample.\n",
    "            n_samples (int): Number of samples of p to generate.\n",
    "            A & B: the same as in hamiltonian_step\n",
    "            max_grad_norm (float or None): The maximum gradient norm to be used for gradient clipping.\n",
    "            reject: if True, we may reject due to energy difference\n",
    "        device (str): Device to use (default='cuda').\n",
    "    \"\"\"\n",
    "    mse = corruption_mse = 0\n",
    "    energy_before_sampling = energy_after_sampling = 0\n",
    "    n_batches = 0\n",
    "    energy_model.eval()\n",
    "\n",
    "    if use_hmc:\n",
    "        n_steps_per_sample = sh['n_steps_per_sample']\n",
    "        n_samples = sh['n_samples']\n",
    "        A = sh['A']\n",
    "        B = sh['B']\n",
    "        max_grad_norm = sh['max_grad_norm']\n",
    "        reject = sh['reject']\n",
    "        bound = sh.get('bound', True)\n",
    "\n",
    "    else:\n",
    "        n_sample_steps = sh['n_sample_steps']\n",
    "        step_lr = sh['step_lr']\n",
    "        langevin_grad_norm = sh['langevin_grad_norm']\n",
    "        add_noise = sh['add_noise']\n",
    "        eps = sh['eps']\n",
    "\n",
    "    pbar = tqdm(total=len(val_loader.dataset))\n",
    "    pbar.set_description('Eval')\n",
    "    for data, _ in val_loader:\n",
    "        n_batches += data.shape[0]\n",
    "        data = data.to(device)\n",
    "        broken_data, mask = corruption(data, type_='ebm')\n",
    "        energy_before_sampling += energy_model(broken_data).sum().item()\n",
    "        if use_hmc:\n",
    "            recovered_img = inpainting_hmc(energy_model, broken_data, mask,\n",
    "                                           n_steps_per_sample, n_samples, A, B, max_grad_norm, reject, bound)\n",
    "        else:\n",
    "            recovered_img = inpainting(energy_model, broken_data, mask,\n",
    "                                   n_sample_steps, step_lr, langevin_grad_norm, add_noise=add_noise, eps=eps)\n",
    "        energy_after_sampling += energy_model(recovered_img).sum().item()\n",
    "\n",
    "        mse += np.mean((data.detach().cpu().numpy().reshape(-1, 28 * 28) - recovered_img.detach().cpu().numpy().reshape(-1, 28 * 28)) ** 2, -1).sum().item()\n",
    "        corruption_mse += np.mean((data.detach().cpu().numpy().reshape(-1, 28 * 28) - broken_data.detach().cpu().numpy().reshape(-1, 28 * 28)) ** 2, -1).sum().item()\n",
    "\n",
    "        pbar.update(data.shape[0])\n",
    "        pbar.set_description('Corruption MSE: {:.6f}, Recovered MSE: {:.6f}, E Before Sampling: {:.6f}, E After Sampling: {:.6f}'.format(\n",
    "            corruption_mse / n_batches, mse / n_batches, energy_before_sampling / n_batches, energy_after_sampling / n_batches))\n",
    "        # show the image\n",
    "        # import matplotlib.pyplot as plt\n",
    "        # plt.imshow(recovered_img[0].detach().cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "        # plt.show()\n",
    "        # break\n",
    "\n",
    "    pbar.close()\n",
    "    return (corruption_mse / n_batches, mse / n_batches, data[:100].detach().cpu(), broken_data[:100].detach().cpu(), recovered_img[:100].detach().cpu())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d62fbcc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "408288173fbc37fcc2d75c0057690de4",
     "grade": false,
     "grade_id": "cell-bfaee9e8110d2da5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02bdcb85",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53e89f05699b12aa2cb1748b4e0b43b7",
     "grade": false,
     "grade_id": "cell-e72fcecf0e87cf84",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(n_epochs, energy_model, train_loader, val_loader, optimizer, use_hmc, sh, l2_alpha, device=device, buffer_maxsize=int(1e4), replay_ratio=0.95, \n",
    "          save_interval=1, max_norm=None):\n",
    "    if use_hmc:\n",
    "        n_steps_per_sample = sh['n_steps_per_sample']\n",
    "        n_samples = sh['n_samples']\n",
    "        A = sh['A']\n",
    "        B = sh['B']\n",
    "        max_grad_norm = sh.get('max_grad_norm', None)\n",
    "        reject = sh.get('reject', False)\n",
    "        bound = sh.get('bound', True)\n",
    "    else:\n",
    "        n_sample_steps = sh['n_sample_steps']\n",
    "        step_lr = sh['step_lr']\n",
    "        langevin_grad_norm = sh['langevin_grad_norm']\n",
    "        langevin_eps = sh['langevin_eps']\n",
    "        eval_step_lr = sh.get('eval_step_lr', None)\n",
    "        if eval_step_lr is None:\n",
    "            eval_step_lr = step_lr\n",
    "    energy_model.to(device)\n",
    "    buffer_maxsize = int(1e4)\n",
    "    buffer_size = buffer_ptr = 0\n",
    "    replay_buffer = torch.zeros(buffer_maxsize, 1, 28, 28)\n",
    "    buffer_size = buffer_ptr = 0\n",
    "    best_mse = np.inf\n",
    "\n",
    "    def show_replay_buffer():\n",
    "        for i in range(4):\n",
    "            idx = np.random.randint(0, buffer_size)\n",
    "            # print(replay_buffer[idx])\n",
    "            plt.imshow(replay_buffer[idx].squeeze().cpu().numpy(), cmap='gray')\n",
    "            # plt.show()\n",
    "            if os.path.exists(f'./ebm/replay_buffer/{epoch + 1}') == False:\n",
    "                os.makedirs(f'./ebm/replay_buffer/{epoch + 1}')\n",
    "            plt.savefig(f'./ebm/replay_buffer/{epoch + 1}/{idx}.png')\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = energy_before = energy_plus = energy_minus = n_batches = 0\n",
    "        pbar = tqdm(total=len(train_loader.dataset))\n",
    "        pbar.set_description('Train')\n",
    "        for i, (x_plus, _) in enumerate(train_loader):\n",
    "            n_batches += x_plus.shape[0]\n",
    "            bs = x_plus.shape[0]\n",
    "            # x_plus shape:  torch.Size([256, 1, 28, 28])\n",
    "\n",
    "            # init negative samples\n",
    "            if buffer_size == 0:\n",
    "                x_minus = torch.rand_like(x_plus)\n",
    "            else:\n",
    "                x_minus = torch.zeros_like(x_plus)\n",
    "\n",
    "                for j in range(bs):\n",
    "                    p = random.random()\n",
    "                    if (p < replay_ratio): \n",
    "                    # Sample a random index from the replay buffer\n",
    "                        idx = np.random.randint(0, buffer_size)\n",
    "                    # Get the corresponding sample from the replay buffer\n",
    "                        x_minus[j] = replay_buffer[idx]\n",
    "                    else:\n",
    "                        x_minus[j] = torch.rand_like(x_plus[j])\n",
    "\n",
    "            x_minus = x_minus.to(device)\n",
    "            energy_before += energy_model(x_minus).sum().item()\n",
    "\n",
    "            # sample negative samples\n",
    "\n",
    "            if use_hmc:\n",
    "                for _ in range(n_samples):\n",
    "                    x_minus = hamiltonian_step(energy_model, x_minus, A, B, n_steps_per_sample, max_grad_norm=max_grad_norm, reject=reject, bound=bound)\n",
    "            else:\n",
    "                for _ in range(n_sample_steps):\n",
    "                    x_minus = langevin_step(energy_model, x_minus, langevin_eps, step_lr=step_lr, max_grad_norm=langevin_grad_norm)\n",
    "\n",
    "            # extend buffer\n",
    "            if buffer_ptr + bs <= buffer_maxsize:\n",
    "                replay_buffer[buffer_ptr: buffer_ptr +\n",
    "                              bs] = ((x_minus * 255).to(torch.uint8).float() / 255).cpu()\n",
    "            else:\n",
    "                x_minus_ = (\n",
    "                    (x_minus * 255).to(torch.uint8).float() / 255).cpu()\n",
    "                replay_buffer[buffer_ptr:] = x_minus_[\n",
    "                    :buffer_maxsize - buffer_ptr]\n",
    "                remaining = bs - (buffer_maxsize - buffer_ptr)\n",
    "                replay_buffer[:remaining] = x_minus_[\n",
    "                    buffer_maxsize - buffer_ptr:]\n",
    "            buffer_ptr = (buffer_ptr + bs) % buffer_maxsize\n",
    "            buffer_size = min(buffer_maxsize, buffer_size + bs)\n",
    "\n",
    "            # compute loss\n",
    "            energy_model.train()\n",
    "            x_plus = x_plus.to(device)\n",
    "            x_minus = x_minus.to(device)\n",
    "            e_plus = energy_model(x_plus)\n",
    "            e_minus = energy_model(x_minus)\n",
    "\n",
    "            # loss = e_plus + torch.clamp(delta - e_minus, min=0) \n",
    "            energy_loss = e_plus - e_minus\n",
    "            # add a term: l2alpha x (e_plus ^ 2 + e_minus ^ 2)\n",
    "            l2_loss = l2_alpha * (e_plus ** 2 + e_minus ** 2)\n",
    "            loss = energy_loss.mean() + l2_loss.mean()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            if max_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(energy_model.parameters(), max_norm=max_norm)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "\n",
    "            ##############################################################################\n",
    "\n",
    "            train_loss += loss.sum().item()\n",
    "            energy_plus += e_plus.sum().item()\n",
    "            energy_minus += e_minus.sum().item()\n",
    "\n",
    "            pbar.update(x_plus.size(0))\n",
    "            pbar.set_description(\"Epoch {}, Train Loss: {:.6f}, \".format(epoch + 1, train_loss / n_batches) +\n",
    "                                 \"E Before Sampling: {:.6f}, \".format(energy_before / n_batches) +\n",
    "                                 \"After: {:.6f}, \".format(energy_minus / n_batches) +\n",
    "                                 \"Ground Truth: {:.6f}\".format(energy_plus / n_batches))\n",
    "        pbar.close()\n",
    "        show_replay_buffer()\n",
    "\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            os.makedirs(f'./ebm/{epoch + 1}', exist_ok=True)\n",
    "            energy_model.eval()\n",
    "            save_model(f'./ebm/{epoch + 1}/ebm.pth',\n",
    "                       energy_model, optimizer, replay_buffer)\n",
    "\n",
    "            # evaluate inpaiting\n",
    "            # feel free to change the inpainting parameters!\n",
    "            if use_hmc:\n",
    "                sh = {\n",
    "                    'n_steps_per_sample': n_steps_per_sample,\n",
    "                    'n_samples': n_samples,\n",
    "                    'A': A,\n",
    "                    'B': B,\n",
    "                    'max_grad_norm': max_grad_norm,\n",
    "                    'reject': reject,\n",
    "                    'bound': bound\n",
    "                }\n",
    "            else:\n",
    "                sh = {\n",
    "                    'n_sample_steps': n_sample_steps,\n",
    "                    'step_lr': eval_step_lr,\n",
    "                    'langevin_grad_norm': langevin_grad_norm,\n",
    "                    'eps': langevin_eps,\n",
    "                    'add_noise': False\n",
    "                }\n",
    "            c_mse, r_mse, original, broken, recovered = evaluate(\n",
    "                energy_model, val_loader, use_hmc, sh)\n",
    "            torchvision.utils.save_image(\n",
    "                original, f\"./ebm/{epoch + 1}/groundtruth.png\", nrow=10)\n",
    "            torchvision.utils.save_image(\n",
    "                broken, f\"./ebm/{epoch + 1}/corrupted.png\", nrow=10)\n",
    "            torchvision.utils.save_image(\n",
    "                recovered, f\"./ebm/{epoch + 1}/recovered.png\", nrow=10)\n",
    "            if r_mse < best_mse:\n",
    "                print(f'Current best MSE: {best_mse} -> {r_mse}')\n",
    "                best_mse = r_mse\n",
    "                save_model('./ebm/ebm_best.pth', energy_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9ded2",
   "metadata": {},
   "source": [
    "Here we define the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "334975fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_MNIST(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (res_layer): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = cnn(hidden_dim=1024).to(device)\n",
    "# model = MlpBackbone((1, 28, 28), 1024).to(device)\n",
    "model = model.to(device)\n",
    "# for param in model.parameters():\n",
    "#     if param.dim() > 1:\n",
    "#         nn.init.orthogonal_(param)\n",
    "\n",
    "\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.0, 0.999))\n",
    "\n",
    "train_loader = DataLoader(train_set, 256, shuffle=True, drop_last=False, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, 500, shuffle=True, drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150ba25",
   "metadata": {},
   "source": [
    "Now start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bfe2663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: -0.018160, E Before Sampling: 2.272072, After: 2.223962, Ground Truth: -3.667976:  14%|▏| 8448/60000 [00:35<03:30, 244.51it/s]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1506626/2057575148.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m       }\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_hmc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# n_sample_steps, step_lr, langevin_eps, langevin_grad_norm, l2_alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1506626/3914534780.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epochs, energy_model, train_loader, val_loader, optimizer, use_hmc, sh, l2_alpha, device, buffer_maxsize, replay_ratio, save_interval, max_norm)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_hmc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                     \u001b[0mx_minus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhamiltonian_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menergy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_minus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps_per_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sample_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1506626/3554006108.py\u001b[0m in \u001b[0;36mhamiltonian_step\u001b[0;34m(energy_model, x, A, B, n_steps, max_grad_norm, reject, bound)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_energy_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menergy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# print('x:',x[0,0,0,0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1506626/3554006108.py\u001b[0m in \u001b[0;36mget_energy_grad\u001b[0;34m(energy_model, x)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0menergy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menergy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0menergy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0menergy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# print('x.grad:', x.grad.min(), x.grad.max())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/sqa24/anaconda3/envs/wgt/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/sqa24/anaconda3/envs/wgt/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: -0.018160, E Before Sampling: 2.272072, After: 2.223962, Ground Truth: -3.667976:  14%|▏| 8448/60000 [00:49<03:30, 244.51it/s]"
     ]
    }
   ],
   "source": [
    "# training hyper-parameters!\n",
    "use_hmc = True\n",
    "epochs = 5\n",
    "l2_alpha = 0.01\n",
    "max_norm = 1.0\n",
    "\n",
    "# when using langevin dynamics\n",
    "n_sample_steps = 60\n",
    "step_lr = 100\n",
    "eps = 5e-3\n",
    "langevin_grad_norm = 0.3\n",
    "replay_ratio = 0.95\n",
    "eval_step_lr = 10\n",
    "\n",
    "# when using hamiltonian dynamics\n",
    "n_steps_per_sample = 10\n",
    "n_samples = 5\n",
    "A = 2e-2\n",
    "B = 2e-4\n",
    "max_grad_norm = 0.03\n",
    "reject = True\n",
    "bound = True\n",
    "\n",
    "if use_hmc:\n",
    "      sh = {\n",
    "            'n_steps_per_sample': n_steps_per_sample,\n",
    "            'n_samples': n_samples,\n",
    "            'A': A,\n",
    "            'B': B,\n",
    "            'max_grad_norm': max_grad_norm,\n",
    "            'reject': reject,\n",
    "            'bound': bound\n",
    "      }\n",
    "\n",
    "else:\n",
    "      sh = {\n",
    "            'n_sample_steps': n_sample_steps,\n",
    "            'step_lr': step_lr,\n",
    "            'langevin_grad_norm': langevin_grad_norm,\n",
    "            'langevin_eps': eps,\n",
    "            'add_noise': False\n",
    "      }\n",
    "\n",
    "train(epochs, model, train_loader, val_loader, optimizer, use_hmc, sh, l2_alpha, device=device, max_norm=max_norm)\n",
    "\n",
    "# n_sample_steps, step_lr, langevin_eps, langevin_grad_norm, l2_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "183040ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_recover(device = device) :\n",
    "    for data, _ in val_loader:\n",
    "        x = data[0]\n",
    "        x = x.to(device)\n",
    "        broken_data, mask = corruption(x, type_='ebm')\n",
    "        # print(broken_data)\n",
    "        # show the energy of broken_data, first resize the broken_data to (1, 1, 28, 28)\n",
    "        broken_data = broken_data.unsqueeze(0)\n",
    "        \n",
    "        # Calculate the energy of the broken_data using the energy_model\n",
    "        model.eval()\n",
    "        energy = model(broken_data)\n",
    "        print(\"Energy of broken_data:\", energy.item())\n",
    "\n",
    "        # Perform inpainting on the broken_data\n",
    "        recovered_img = inpainting(model, broken_data, mask, 500, 0.05, langevin_grad_norm)\n",
    "        print(recovered_img - broken_data)\n",
    "        # show the energy of recovered_img\n",
    "        recovered_img = recovered_img.squeeze(0)\n",
    "        recovered_img = recovered_img.unsqueeze(0)\n",
    "        energy = model(recovered_img)\n",
    "        print(\"Energy of recovered_img:\", energy.item())\n",
    "        # show the recovered image and the corrupted image\n",
    "        plt.imshow(recovered_img.squeeze().cpu().numpy(), cmap='gray')\n",
    "        plt.show()\n",
    "        plt.imshow(broken_data.squeeze().cpu().numpy(), cmap='gray')\n",
    "\n",
    "        # show the image\n",
    "        plt.imshow(broken_data[0].squeeze().cpu().numpy(), cmap='gray')\n",
    "        break\n",
    "# show_recover()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d9ad1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "346cba624d53af3f3fed53aab993f261",
     "grade": false,
     "grade_id": "cell-c20c624e7ec0d633",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4ed12bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation parameters!\n",
    "use_hmc = 1\n",
    "\n",
    "# when using langevin dynamics\n",
    "n_sample_steps = 60\n",
    "step_lr = 50\n",
    "langevin_grad_norm = 0.3\n",
    "add_noise = True\n",
    "eps = 0.02\n",
    "\n",
    "# when using hamiltonian dynamics\n",
    "n_steps_per_sample = 10\n",
    "n_samples = 10\n",
    "A = 2e-2\n",
    "B = 2e-4\n",
    "max_grad_norm = 0.03\n",
    "reject = True\n",
    "bound = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "988fa737",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a52957140b64eb164a8f5bc3ecee0a5c",
     "grade": false,
     "grade_id": "cell-a3504d53a9a04b33",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corruption MSE: 0.062915, Recovered MSE: 0.010558, E Before Sampling: 0.002118, E After Sampling: -0.002617:  15%|▏| 1500/10000 [00:10<01:00, 141.63it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1505078/1878492825.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ebm/ebm_best.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m corruption_mse, mse, original, broken, recovered = evaluate(\n\u001b[0;32m---> 23\u001b[0;31m     model, val_loader, use_hmc, sh)\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./ebm/eval'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1505078/2318775672.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(energy_model, val_loader, use_hmc, sh, device)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_hmc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             recovered_img = inpainting_hmc(energy_model, broken_data, mask,\n\u001b[0;32m---> 54\u001b[0;31m                                            n_steps_per_sample, n_samples, A, B, max_grad_norm, reject, bound)\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             recovered_img = inpainting(energy_model, broken_data, mask,\n",
      "\u001b[0;32m/tmp/ipykernel_1505078/2675450041.py\u001b[0m in \u001b[0;36minpainting_hmc\u001b[0;34m(energy_model, x, mask, n_steps_per_sample, n_samples, A, B, max_grad_norm, reject, bound)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_steps_per_sample\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_energy_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menergy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mreverse_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# print('x:',x[0,0,13,15])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1505078/2380007066.py\u001b[0m in \u001b[0;36mget_energy_grad\u001b[0;34m(energy_model, x)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menergy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0menergy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0menergy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# print('x.grad:', x.grad.min(), x.grad.max())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/sqa24/anaconda3/envs/wgt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshare_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if use_hmc:\n",
    "    sh = {\n",
    "        'n_steps_per_sample': n_steps_per_sample,\n",
    "        'n_samples': n_samples,\n",
    "        'A': A,\n",
    "        'B': B,\n",
    "        'max_grad_norm': max_grad_norm,\n",
    "        'reject': reject,\n",
    "        'bound': bound\n",
    "    }\n",
    "\n",
    "else:\n",
    "    sh = {\n",
    "        'n_sample_steps': n_sample_steps,\n",
    "        'step_lr': step_lr,\n",
    "        'langevin_grad_norm': langevin_grad_norm,\n",
    "        'add_noise': add_noise,\n",
    "        'eps': eps\n",
    "    }\n",
    "\n",
    "model.load_state_dict(load_model('./ebm/ebm_best.pth')[0])\n",
    "corruption_mse, mse, original, broken, recovered = evaluate(\n",
    "    model, val_loader, use_hmc, sh)\n",
    "os.makedirs(f'./ebm/eval', exist_ok=True)\n",
    "\n",
    "torchvision.utils.save_image(\n",
    "                original, f\"./ebm/eval/groundtruth.png\", nrow=10)\n",
    "torchvision.utils.save_image(\n",
    "                broken, f\"./ebm/eval/corrupted.png\", nrow=10)\n",
    "s = f\"./ebm/eval/recovered_langevin.png\" if use_hmc == 0 else f\"./ebm/eval/recovered_hmc.png\"\n",
    "torchvision.utils.save_image(\n",
    "                recovered, s, nrow=10)\n",
    "\n",
    "\n",
    "print(f'Corruption MSE: {corruption_mse}')\n",
    "print(f'Recovered MSE: {mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a6357",
   "metadata": {},
   "source": [
    "hmc 5*10 36.8s\n",
    "langevin 100 1m2.8s\n",
    "langevin 60 39.1s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
