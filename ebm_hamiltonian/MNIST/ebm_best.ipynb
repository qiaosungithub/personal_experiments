{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718d6fe6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b66c03c90ce725319f0691dfb29845ac",
     "grade": false,
     "grade_id": "cell-9c430af5d8d383e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Energy-Based Model, with Hamiltonian Monte Carlo and temperature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8228e39",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8faaef554f2902c0d2a24e870f8a80c",
     "grade": false,
     "grade_id": "cell-1c233faf26d419be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "# from matplotlib import rcParams\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# # figure size in inches optional\n",
    "# rcParams['figure.figsize'] = 11, 8\n",
    "\n",
    "# # read images\n",
    "# img_A = mpimg.imread('./ebm/groundtruth.png')\n",
    "# img_B = mpimg.imread('./ebm/corrupted.png')\n",
    "\n",
    "# # display images\n",
    "# fig, ax = plt.subplots(1, 2)\n",
    "# ax[0].imshow(img_A)\n",
    "# ax[1].imshow(img_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a90a8be",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "629c76063b8cf64b9021654fbe717d41",
     "grade": false,
     "grade_id": "cell-527c7725f3508ba0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Tips\n",
    "\n",
    "+ Training with naive contrastive-divergence algorithm will make your model diverge quickly (think about why). Therefore, you need to add a L2 regularization term $\\alpha(E_\\theta(x+)^2 + E_\\theta(x-)^2)$ to stabilize training.\n",
    "\n",
    "+ Keep track of the generated samples during training to get a sense of how well your model is evolving.\n",
    "\n",
    "+ You can take a look at the paper [Implicit Generation and Generalization in Energy Based Models](https://arxiv.org/pdf/1903.08689.pdf) to learn more about useful tricks to get your model working.\n",
    "\n",
    "+ Make sure your code runs fine with the evaluation cell in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd040c70",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54854fcdc1556d353b55bc4d1a133674",
     "grade": false,
     "grade_id": "cell-2b4bea3e44a7b81b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Set Up Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca3738",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0bb447e0084709f0b673b1e91ba0aa1a",
     "grade": false,
     "grade_id": "cell-291232b1c59e4f02",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you use Colab in this coding project, please uncomment the code, fill the `GOOGLE_DRIVE_PATH_AFTER_MYDRIVE` and run the following cells to mount your Google drive. Then, the notebook can find the required file (i.e., utils.py). If you run the notebook locally, you can skip the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c2354b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b34bc8b23f9c8e480a9671ef3453e7ac",
     "grade": false,
     "grade_id": "cell-a551fcc5ff27fb87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(GOOGLE_DRIVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6cd2080",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d5d6f96e1d7ce5df1315172b57173de",
     "grade": false,
     "grade_id": "cell-e11eaf041d72deda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good luck!\n"
     ]
    }
   ],
   "source": [
    "from ebm_hamiltonian.models.utils import hello\n",
    "hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf1d5cb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc6d9d087b7f8aedc3401222f717bb07",
     "grade": false,
     "grade_id": "cell-c0b91f0d2b7ecc80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_168271/1944725143.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "from ebm_hamiltonian.models.utils import save_model, load_model, corruption, train_set, val_set\n",
    "\n",
    "seed = 114\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "os.makedirs('./ebm', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b76802",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dbb5921ccbc0e1e14fd40df09afebcac",
     "grade": false,
     "grade_id": "cell-f28aaf301b501410",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## MLP Model\n",
    "\n",
    "We have provided an example MLP implementation. Feel free to modify the following cell the implement your own model.\n",
    "\n",
    "**Note that your model should be an MLP!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ca4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MlpBackbone(nn.Module):\n",
    "#     def __init__(self, input_shape, hidden_size, activation=nn.functional.elu):\n",
    "#         super(MlpBackbone, self).__init__()\n",
    "#         self.input_shape = input_shape  # (C, H, W)\n",
    "#         self.hidden_size = hidden_size\n",
    "#         # Layers\n",
    "#         self.fc1 = nn.Linear(np.prod(self.input_shape), self.hidden_size)\n",
    "#         self.bn1 = nn.BatchNorm1d(self.hidden_size)  # BatchNorm layer\n",
    "#         self.fc2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "#         self.bn2 = nn.BatchNorm1d(self.hidden_size)  # BatchNorm layer\n",
    "#         self.fc3 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "#         self.bn3 = nn.BatchNorm1d(self.hidden_size)  # BatchNorm layer\n",
    "#         self.fc4 = nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "#         self.activation = activation\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.flatten(x, start_dim=1)\n",
    "#         x = self.activation(self.bn1(self.fc1(x)))  # Apply BatchNorm after the first linear layer\n",
    "#         x = self.activation(self.bn2(self.fc2(x)))  # Apply BatchNorm after the second linear layer\n",
    "#         x = self.activation(self.bn3(self.fc3(x)))  # Apply BatchNorm after the third linear layer\n",
    "#         out = torch.tanh(self.fc4(x))  # Apply tanh activation to the last linear layer\n",
    "#         return out\n",
    "\n",
    "# class MlpBackbone(nn.Module):\n",
    "#     def __init__(self, input_shape, hidden_size, activation=nn.functional.elu):\n",
    "#         super(MlpBackbone, self).__init__()\n",
    "#         self.input_shape = input_shape  # (C, H, W)\n",
    "#         self.hidden_size = hidden_size\n",
    "#         # Layers\n",
    "#         self.conv1 = nn.Conv2d(input_shape[0], 16, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.fc1 = nn.Linear(32 * input_shape[1] * input_shape[2], self.hidden_size)\n",
    "#         self.bn1 = nn.BatchNorm1d(self.hidden_size)  # BatchNorm layer\n",
    "#         self.fc2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "#         self.bn2 = nn.BatchNorm1d(self.hidden_size)  # BatchNorm layer\n",
    "#         self.fc3 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "#         self.bn3 = nn.BatchNorm1d(self.hidden_size)  # BatchNorm layer\n",
    "#         self.fc4 = nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "#         self.activation = activation\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.activation(self.conv1(x))\n",
    "#         x = self.activation(self.conv2(x))\n",
    "#         x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "#         x = self.activation(self.bn1(self.fc1(x)))  # Apply BatchNorm after the first linear layer\n",
    "#         x = self.activation(self.bn2(self.fc2(x)))  # Apply BatchNorm after the second linear layer\n",
    "#         x = self.activation(self.bn3(self.fc3(x)))  # Apply BatchNorm after the third linear layer\n",
    "#         out = torch.tanh(self.fc4(x))  # Apply tanh activation to the last linear layer\n",
    "#         return out\n",
    "    \n",
    "# class MlpBackbone(nn.Module):\n",
    "#     def __init__(self, input_shape, hidden_size, activation=nn.functional.elu):\n",
    "#         super(MlpBackbone, self).__init__()\n",
    "#         self.input_shape = input_shape  # (C, H, W)\n",
    "#         self.hidden_size = hidden_size\n",
    "#         # Layers\n",
    "#         self.conv1 = nn.Conv2d(input_shape[0], 16, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.resnet = torchvision.models.resnet18(pretrained=False)\n",
    "#         self.fc1 = nn.Linear(512, self.hidden_size)\n",
    "#         self.bn1 = nn.BatchNorm1d(self.hidden_size)  # BatchNorm layer\n",
    "#         self.fc2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "#         self.bn2 = nn.BatchNorm1d(self.hidden_size)  # BatchNorm layer\n",
    "#         self.fc3 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "#         self.bn3 = nn.BatchNorm1d(self.hidden_size)  # BatchNorm layer\n",
    "#         self.fc4 = nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "#         self.activation = activation\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.activation(self.conv1(x))\n",
    "#         x = self.activation(self.conv2(x))\n",
    "#         x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "#         x = self.resnet(x)\n",
    "#         x = self.activation(self.bn1(self.fc1(x)))  # Apply BatchNorm after the first linear layer\n",
    "#         x = self.activation(self.bn2(self.fc2(x)))  # Apply BatchNorm after the second linear layer\n",
    "#         x = self.activation(self.bn3(self.fc3(x)))  # Apply BatchNorm after the third linear layer\n",
    "#         out = torch.tanh(self.fc4(x))  # Apply tanh activation to the last linear layer\n",
    "#         return out\n",
    "    \n",
    "def Swish(x):\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reshape):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        out_channels = in_channels * 2 if reshape else in_channels\n",
    "        stride = 2 if reshape else 1\n",
    "        self.conv_block = conv_block(in_channels, out_channels, stride=stride)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        if reshape:\n",
    "            self.residual_transform = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2)\n",
    "        else:\n",
    "            self.residual_transform = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv_block(x)\n",
    "        if self.residual_transform is not None:\n",
    "            residual = self.residual_transform(residual)\n",
    "        out = out + residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MlpBackbone(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_size, activation=nn.functional.elu):\n",
    "        super(MlpBackbone, self).__init__()\n",
    "        self.input_shape = input_shape  # (C, H, W)\n",
    "        self.hidden_size = hidden_size\n",
    "        # Layers\n",
    "        self.conv1 = nn.Conv2d(input_shape[0], 8, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(8)  # BatchNorm layer\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)  # BatchNorm layer\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv3 = nn.Conv2d(16, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)  # BatchNorm layer\n",
    "        self.resnet1 = ResNetBlock(64, reshape=False)\n",
    "        self.resnet2 = ResNetBlock(64, reshape=False)\n",
    "        self.resnet3 = ResNetBlock(64, reshape=False)\n",
    "        self.fc1 = nn.Linear(64 * 14 * 14, self.hidden_size)\n",
    "        self.bn4 = nn.BatchNorm1d(self.hidden_size)  # BatchNorm layer\n",
    "        self.fc2 = nn.Linear(self.hidden_size, 1)\n",
    "        # self.bn5 = nn.BatchNorm1d(self.hidden_size)  # BatchNorm layer\n",
    "        # self.fc3 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        # self.bn6 = nn.BatchNorm1d(self.hidden_size)  # BatchNorm layer\n",
    "        # self.fc4 = nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = Swish(self.conv1(x))\n",
    "        x = Swish(self.conv2(x))\n",
    "        x = self.avgpool(x)\n",
    "        x = Swish(self.conv3(x))\n",
    "        x = self.resnet1(x)\n",
    "        x = self.resnet2(x)\n",
    "        x = self.resnet3(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = Swish(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b351bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MlpBackbone(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (resnet1): ResNetBlock(\n",
      "    (conv_block): conv_block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (resnet2): ResNetBlock(\n",
      "    (conv_block): conv_block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (resnet3): ResNetBlock(\n",
      "    (conv_block): conv_block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=12544, out_features=128, bias=True)\n",
      "  (bn4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(MlpBackbone((1, 28, 28), 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d61159f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd456d1555c954ff15d4cfcb44b144f5",
     "grade": false,
     "grade_id": "cell-cafb02a0cc941c58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Sampling\n",
    "\n",
    "Implement Langevin dynamics in the following cell. Pay attention to the gradients of both your energy model and input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b704099a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91d2744d6a964f70ff2c85c161f92c9f",
     "grade": false,
     "grade_id": "cell-afd44e44fcd9d650",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def langevin_step(energy_model, x, step_lr, eps, max_grad_norm):\n",
    "    \"\"\"\n",
    "    Perform one step of Langevin dynamics sampling.\n",
    "\n",
    "    Args:\n",
    "        energy_model (nn.Module): The energy-based model used for sampling.\n",
    "        x (torch.Tensor): The input tensor to update via Langevin dynamics.\n",
    "        step_lr (float): The learning rate of the optimizer used to update the input.\n",
    "        eps (float): The step size of the Langevin dynamics update.\n",
    "        max_grad_norm (float or None): The maximum norm of the gradient for gradient clipping.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The updated input tensor after one step of Langevin dynamics.\n",
    "    \"\"\"\n",
    "    y = x.clone().detach()\n",
    "    y.requires_grad = True\n",
    "\n",
    "    energy = energy_model(y)\n",
    "    energy.sum().backward()\n",
    "\n",
    "    gradient = y.grad\n",
    "\n",
    "    # 添加高斯噪声\n",
    "    # noise = 0\n",
    "    noise = torch.randn_like(x) * torch.sqrt(torch.tensor(eps).to(x.device))\n",
    "\n",
    "    # 如果提供了max_grad_norm，就裁剪梯度\n",
    "    # if max_grad_norm is not None:\n",
    "    #     gradient = gradient.clamp(-max_grad_norm, max_grad_norm)\n",
    "\n",
    "    # 更新x_new\n",
    "    x_new = x - step_lr * gradient + noise\n",
    "    x_new = torch.clamp(x_new, 0, 1)  # Ensure pixel values are between 0 and 1\n",
    "\n",
    "    return x_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba5264a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test() :\n",
    "    x = torch.randn(256, 1, 28, 28)\n",
    "    # print(x)\n",
    "    model = MlpBackbone((1, 28, 28), 1024)\n",
    "    print(\"energy:\" ,model(x).sum().item())\n",
    "    for i in range(60):\n",
    "        x = langevin_step(model, x, 0.002, 0.01, 0.03)\n",
    "        # print(x)\n",
    "        print(\"energy:\" ,model(x).sum().item())\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1fdbf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5171faedb56d4b5f97620596006e4525",
     "grade": false,
     "grade_id": "cell-508a10378fa57a85",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Inpainting\n",
    "\n",
    "Implement the inpainting procedure. Think about the difference between sampling and inpainting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7ed1856",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15d3e13b437efa0e295540e214b3a612",
     "grade": false,
     "grade_id": "cell-5fce3238f7ff50db",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def inpainting(energy_model, x, mask, n_steps, step_lr, max_grad_norm):\n",
    "    \"\"\"\n",
    "    Inpainting function that completes an image given a masked input using Langevin dynamics.\n",
    "\n",
    "    Args:\n",
    "        energy_model (nn.Module): The energy-based model used to generate the image.\n",
    "        x (torch.Tensor): The input tensor, a masked image that needs to be completed.\n",
    "        mask (torch.Tensor): The mask tensor, with the same shape as x, where 1 indicates the corresponding\n",
    "                             pixel is visible and 0 indicates it is missing.\n",
    "        n_steps (int): The number of steps of Langevin dynamics to run.\n",
    "        step_lr (float): The step size of Langevin dynamics.\n",
    "        max_grad_norm (float or None): The maximum gradient norm to be used for gradient clipping. If None, \n",
    "                                       no gradient clipping is performed.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The completed image tensor.\n",
    "    \"\"\"\n",
    "    reverse_mask = 1-mask\n",
    "\n",
    "\n",
    "    for _ in range(n_steps):\n",
    "        out = x.clone().detach()\n",
    "        out.requires_grad = True\n",
    "        energy = energy_model(out)\n",
    "        energy.sum().backward()\n",
    "        gradient = out.grad\n",
    "        if max_grad_norm is not None:\n",
    "            gradient = gradient.clamp(-max_grad_norm, max_grad_norm)\n",
    "        noise = 0\n",
    "        # noise = torch.randn_like(x) * torch.sqrt(torch.tensor(2*step_lr).to(x.device)) * reverse_mask\n",
    "        x = x - step_lr * gradient * reverse_mask + noise\n",
    "        x = torch.clamp(x, 0, 1)  # Ensure pixel values are between 0 and 1\n",
    "\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "593bd650",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6153ff029424a3266efd4b44329a1223",
     "grade": false,
     "grade_id": "cell-e4f7157f3a2421d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(energy_model, val_loader, n_sample_steps, step_lr, langevin_grad_norm, \n",
    "             device='cuda'):\n",
    "    \"\"\"\n",
    "    Evaluates the energy model on the validation set and returns the corruption MSE,\n",
    "    recovered MSE, corrupted images, and recovered images for visualization.\n",
    "\n",
    "    Args:\n",
    "        energy_model (nn.Module): Trained energy-based model.\n",
    "        val_loader (torch.utils.data.DataLoader): Validation data loader.\n",
    "        n_sample_steps (int): Number of Langevin dynamics steps to take when sampling.\n",
    "        step_lr (float): Learning rate to use during Langevin dynamics.\n",
    "        langevin_grad_norm (float): Maximum L2 norm of the Langevin dynamics gradient.\n",
    "        device (str): Device to use (default='cuda').\n",
    "    \"\"\"\n",
    "    mse = corruption_mse = 0\n",
    "    energy_before_sampling = energy_after_sampling = 0\n",
    "    n_batches = 0\n",
    "    energy_model.eval()\n",
    "\n",
    "    pbar = tqdm(total=len(val_loader.dataset))\n",
    "    pbar.set_description('Eval')\n",
    "    for data, _ in val_loader:\n",
    "        n_batches += data.shape[0]\n",
    "        data = data.to(device)\n",
    "        broken_data, mask = corruption(data, type_='ebm')\n",
    "        energy_before_sampling += energy_model(broken_data).sum().item()\n",
    "        recovered_img = inpainting(energy_model, broken_data, mask,\n",
    "                                   n_sample_steps, step_lr, langevin_grad_norm)\n",
    "        energy_after_sampling += energy_model(recovered_img).sum().item()\n",
    "\n",
    "        mse += np.mean((data.detach().cpu().numpy().reshape(-1, 28 * 28) - recovered_img.detach().cpu().numpy().reshape(-1, 28 * 28)) ** 2, -1).sum().item()\n",
    "        corruption_mse += np.mean((data.detach().cpu().numpy().reshape(-1, 28 * 28) - broken_data.detach().cpu().numpy().reshape(-1, 28 * 28)) ** 2, -1).sum().item()\n",
    "\n",
    "        pbar.update(data.shape[0])\n",
    "        pbar.set_description('Corruption MSE: {:.6f}, Recovered MSE: {:.6f}, Energy Before Sampling: {:.6f}, Energy After Sampling: {:.6f}'.format(\n",
    "            corruption_mse / n_batches, mse / n_batches, energy_before_sampling / n_batches, energy_after_sampling / n_batches))\n",
    "\n",
    "    pbar.close()\n",
    "    return (corruption_mse / n_batches, mse / n_batches, data[:100].detach().cpu(), broken_data[:100].detach().cpu(), recovered_img[:100].detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d62fbcc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "408288173fbc37fcc2d75c0057690de4",
     "grade": false,
     "grade_id": "cell-bfaee9e8110d2da5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Training\n",
    "Fill the missing parts in the `train` function. There are some comments implying what to do in the corresponding blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02bdcb85",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53e89f05699b12aa2cb1748b4e0b43b7",
     "grade": false,
     "grade_id": "cell-e72fcecf0e87cf84",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(n_epochs, energy_model, train_loader, val_loader, optimizer, n_sample_steps, step_lr, langevin_eps, \n",
    "          langevin_grad_norm, l2_alpha,\n",
    "          device='cuda', buffer_maxsize=int(1e4), replay_ratio=0.95 , save_interval=1, delta=300):\n",
    "    energy_model.to(device)\n",
    "    buffer_maxsize = int(1e4)\n",
    "    buffer_size = buffer_ptr = 0\n",
    "    replay_buffer = torch.zeros(buffer_maxsize, 1, 28, 28)\n",
    "    buffer_size = buffer_ptr = 0\n",
    "    best_mse = np.inf\n",
    "\n",
    "    def show_replay_buffer() :\n",
    "        for i in range(2):\n",
    "            idx = np.random.randint(0, buffer_size)\n",
    "            # print(replay_buffer[idx])\n",
    "            plt.imshow(replay_buffer[idx].squeeze().cpu().numpy(), cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = energy_before = energy_plus = energy_minus = n_batches = 0\n",
    "        pbar = tqdm(total=len(train_loader.dataset))\n",
    "        pbar.set_description('Train')\n",
    "        for i, (x_plus, _) in enumerate(train_loader):\n",
    "            n_batches += x_plus.shape[0]\n",
    "            bs = x_plus.shape[0]\n",
    "            # print(\"x_plus shape: \", x_plus.shape)\n",
    "            # x_plus shape:  torch.Size([256, 1, 28, 28])\n",
    "\n",
    "            # init negative samples\n",
    "            if buffer_size == 0:\n",
    "                x_minus = torch.rand_like(x_plus)\n",
    "            else:\n",
    "                ##############################################################################\n",
    "\n",
    "\n",
    "                x_minus = torch.zeros_like(x_plus)\n",
    "\n",
    "                for j in range(bs):\n",
    "                    p = random.random()\n",
    "                    if (p < replay_ratio): # This can be changed\n",
    "                    # Sample a random index from the replay buffer\n",
    "                        idx = np.random.randint(0, buffer_size)\n",
    "                    # Get the corresponding sample from the replay buffer\n",
    "                        x_minus[j] = replay_buffer[idx]\n",
    "                    else :\n",
    "                        x_minus[j] = torch.rand_like(x_plus[j])\n",
    "                \n",
    "                ##############################################################################\n",
    "\n",
    "            x_minus = x_minus.to(device)\n",
    "            # print(\"x_minus shape: \", x_minus.shape)\n",
    "\n",
    "            energy_before += energy_model(x_minus).sum().item()\n",
    "\n",
    "            # sample negative samples\n",
    "            ##############################################################################\n",
    "\n",
    "            for stepsss in range(n_sample_steps):\n",
    "                x_minus = langevin_step(energy_model, x_minus, step_lr, langevin_eps, langevin_grad_norm)\n",
    "\n",
    "            ##############################################################################\n",
    "\n",
    "            # extend buffer\n",
    "            if buffer_ptr + bs <= buffer_maxsize:\n",
    "                replay_buffer[buffer_ptr: buffer_ptr +\n",
    "                              bs] = ((x_minus * 255).to(torch.uint8).float() / 255).cpu()\n",
    "            else:\n",
    "                x_minus_ = (\n",
    "                    (x_minus * 255).to(torch.uint8).float() / 255).cpu()\n",
    "                replay_buffer[buffer_ptr:] = x_minus_[\n",
    "                    :buffer_maxsize - buffer_ptr]\n",
    "                remaining = bs - (buffer_maxsize - buffer_ptr)\n",
    "                replay_buffer[:remaining] = x_minus_[\n",
    "                    buffer_maxsize - buffer_ptr:]\n",
    "            buffer_ptr = (buffer_ptr + bs) % buffer_maxsize\n",
    "            buffer_size = min(buffer_maxsize, buffer_size + bs)\n",
    "\n",
    "            # compute loss\n",
    "            energy_model.train()\n",
    "            x_plus = x_plus.to(device)\n",
    "            x_minus = x_minus.to(device)\n",
    "            e_plus = energy_model(x_plus)\n",
    "            e_minus = energy_model(x_minus)\n",
    "            ##############################################################################\n",
    "\n",
    "\n",
    "            # loss = e_plus + torch.clamp(delta - e_minus, min=0) \n",
    "            loss = e_plus - e_minus\n",
    "            # add a term: l2alpha times e_plus ^ 2 + e_minus ^ 2\n",
    "            # e_plus = torch.clamp(e_plus, -0.999, 0.999)\n",
    "            # e_minus = torch.clamp(e_minus, -0.999, 0.999)\n",
    "            l2_loss = l2_alpha * (e_plus ** 2 + e_minus ** 2).mean()\n",
    "            loss_mean = loss.mean()\n",
    "            loss_mean += l2_loss\n",
    "            optimizer.zero_grad()\n",
    "            loss_mean.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(energy_model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "\n",
    "            ##############################################################################\n",
    "\n",
    "            train_loss += loss.sum().item()\n",
    "            energy_plus += e_plus.sum().item()\n",
    "            energy_minus += e_minus.sum().item()\n",
    "\n",
    "            pbar.update(x_plus.size(0))\n",
    "            pbar.set_description(\"Train Epoch {}, Train Loss: {:.6f}, \".format(epoch + 1, train_loss / n_batches) +\n",
    "                                 \"Energy Before Sampling: {:.6f}, \".format(energy_before / n_batches) +\n",
    "                                 \"Energy After Sampling: {:.6f}, \".format(energy_minus / n_batches) +\n",
    "                                 \"Energy of Ground Truth: {:.6f}\".format(energy_plus / n_batches))\n",
    "        pbar.close()\n",
    "        show_replay_buffer()\n",
    "\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            os.makedirs(f'./ebm/{epoch + 1}', exist_ok=True)\n",
    "            energy_model.eval()\n",
    "            save_model(f'./ebm/{epoch + 1}/ebm.pth',\n",
    "                       energy_model, optimizer, replay_buffer)\n",
    "\n",
    "            # evaluate inpaiting\n",
    "            # feel free to change the inpainting parameters!\n",
    "            c_mse, r_mse, original, broken, recovered = evaluate(energy_model, val_loader,\n",
    "                                                                 100, 5, 0.1, device=device)\n",
    "            torchvision.utils.save_image(\n",
    "                original, f\"./ebm/{epoch + 1}/groundtruth.png\", nrow=10)\n",
    "            torchvision.utils.save_image(\n",
    "                broken, f\"./ebm/{epoch + 1}/corrupted.png\", nrow=10)\n",
    "            torchvision.utils.save_image(\n",
    "                recovered, f\"./ebm/{epoch + 1}/recovered.png\", nrow=10)\n",
    "            if r_mse < best_mse:\n",
    "                print(f'Current best MSE: {best_mse} -> {r_mse}')\n",
    "                best_mse = r_mse\n",
    "                save_model('./ebm/ebm_best.pth', energy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "334975fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMlpBackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# for param in model.parameters():\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     if param.dim() > 1:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#         nn.init.orthogonal_(param)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "Cell \u001b[0;32mIn[6], line 139\u001b[0m, in \u001b[0;36mMlpBackbone.__init__\u001b[0;34m(self, input_shape, hidden_size, activation)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet2 \u001b[38;5;241m=\u001b[39m ResNetBlock(\u001b[38;5;241m64\u001b[39m, reshape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet3 \u001b[38;5;241m=\u001b[39m ResNetBlock(\u001b[38;5;241m64\u001b[39m, reshape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1 \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn4 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBatchNorm1d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)  \u001b[38;5;66;03m# BatchNorm layer\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/DYY/lib/python3.10/site-packages/torch/nn/modules/linear.py:104\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DYY/lib/python3.10/site-packages/torch/nn/modules/linear.py:110\u001b[0m, in \u001b[0;36mLinear.reset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m         fan_in, _ \u001b[38;5;241m=\u001b[39m init\u001b[38;5;241m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n",
      "File \u001b[0;32m~/anaconda3/envs/DYY/lib/python3.10/site-packages/torch/nn/init.py:460\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity, generator)\u001b[0m\n\u001b[1;32m    458\u001b[0m bound \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m) \u001b[38;5;241m*\u001b[39m std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MlpBackbone((1, 28, 28), 1024).to(device)\n",
    "# for param in model.parameters():\n",
    "#     if param.dim() > 1:\n",
    "#         nn.init.orthogonal_(param)\n",
    "\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.0, 0.999))\n",
    "\n",
    "train_loader = DataLoader(train_set, 256, shuffle=True, drop_last=False, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, 500, shuffle=True, drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150ba25",
   "metadata": {},
   "source": [
    "Now you can start your training. Please keep in mind that this cell may **NOT** be run when we evaluate your assignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dd96bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mnist() :\n",
    "    for data, _ in val_loader:\n",
    "        x = data[0]\n",
    "        broken_data, mask = corruption(x, type_='ebm')\n",
    "        print(broken_data)\n",
    "        print(mask)\n",
    "        # show the image\n",
    "        plt.imshow(broken_data[0].squeeze().cpu().numpy(), cmap='gray')\n",
    "        break\n",
    "# show_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bfe2663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b12d6ceda0c423ebd3836f6a8161030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m l2_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m      7\u001b[0m replay_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.95\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_sample_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_sample_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlangevin_eps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlangevin_grad_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlangevin_grad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml2_alpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m      \u001b[49m\u001b[43mreplay_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_ratio\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 61\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(n_epochs, energy_model, train_loader, val_loader, optimizer, n_sample_steps, step_lr, langevin_eps, langevin_grad_norm, l2_alpha, device, buffer_maxsize, replay_ratio, save_interval, delta)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# sample negative samples\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m##############################################################################\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stepsss \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_sample_steps):\n\u001b[0;32m---> 61\u001b[0m     x_minus \u001b[38;5;241m=\u001b[39m \u001b[43mlangevin_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43menergy_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_minus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlangevin_eps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlangevin_grad_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m##############################################################################\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extend buffer\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer_ptr \u001b[38;5;241m+\u001b[39m bs \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m buffer_maxsize:\n",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m, in \u001b[0;36mlangevin_step\u001b[0;34m(energy_model, x, step_lr, eps, max_grad_norm)\u001b[0m\n\u001b[1;32m     21\u001b[0m gradient \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mgrad\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 添加高斯噪声\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# noise = 0\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(x) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 如果提供了max_grad_norm，就裁剪梯度\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# if max_grad_norm is not None:\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#     gradient = gradient.clamp(-max_grad_norm, max_grad_norm)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# 更新x_new\u001b[39;00m\n\u001b[1;32m     32\u001b[0m x_new \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m-\u001b[39m step_lr \u001b[38;5;241m*\u001b[39m gradient \u001b[38;5;241m+\u001b[39m noise\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# feel free the change training hyper-parameters!\n",
    "n_sample_steps = 100\n",
    "step_lr = 10\n",
    "eps = 0.005\n",
    "langevin_grad_norm = 0.3\n",
    "l2_alpha = 0.01\n",
    "replay_ratio = 0.95\n",
    "train(10, model, train_loader, val_loader, optimizer, n_sample_steps=n_sample_steps, step_lr=step_lr, \n",
    "      langevin_eps=eps, langevin_grad_norm=langevin_grad_norm, l2_alpha=l2_alpha, device=device, \n",
    "      replay_ratio=replay_ratio)\n",
    "\n",
    "\n",
    "# n_sample_steps, step_lr, langevin_eps, langevin_grad_norm, l2_alpha\n",
    "\n",
    "# when testing, we find that step_lr = 100 also works well (if eval_step_lr is also 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "183040ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_recover(device = \"cuda\") :\n",
    "    for data, _ in val_loader:\n",
    "        x = data[0]\n",
    "        x = x.to(device)\n",
    "        broken_data, mask = corruption(x, type_='ebm')\n",
    "        # print(broken_data)\n",
    "        # show the energy of broken_data, first resize the broken_data to (1, 1, 28, 28)\n",
    "        broken_data = broken_data.unsqueeze(0)\n",
    "        \n",
    "        # Calculate the energy of the broken_data using the energy_model\n",
    "        model.eval()\n",
    "        energy = model(broken_data)\n",
    "        print(\"Energy of broken_data:\", energy.item())\n",
    "\n",
    "        # Perform inpainting on the broken_data\n",
    "        recovered_img = inpainting(model, broken_data, mask, 500, 0.05, langevin_grad_norm)\n",
    "        print(recovered_img - broken_data)\n",
    "        # show the energy of recovered_img\n",
    "        recovered_img = recovered_img.squeeze(0)\n",
    "        recovered_img = recovered_img.unsqueeze(0)\n",
    "        energy = model(recovered_img)\n",
    "        print(\"Energy of recovered_img:\", energy.item())\n",
    "        # show the recovered image and the corrupted image\n",
    "        plt.imshow(recovered_img.squeeze().cpu().numpy(), cmap='gray')\n",
    "        plt.show()\n",
    "        plt.imshow(broken_data.squeeze().cpu().numpy(), cmap='gray')\n",
    "\n",
    "        # show the image\n",
    "        # plt.imshow(broken_data[0].squeeze().cpu().numpy(), cmap='gray')\n",
    "        break\n",
    "# show_recover()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d9ad1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "346cba624d53af3f3fed53aab993f261",
     "grade": false,
     "grade_id": "cell-c20c624e7ec0d633",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Make sure you can run the following evaluation cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4ed12bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to change evaluation parameters!\n",
    "# inpainting parameters are not necessarily the same as sampling parameters\n",
    "n_sample_steps = 100\n",
    "step_lr = 5\n",
    "langevin_grad_norm = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "988fa737",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a52957140b64eb164a8f5bc3ecee0a5c",
     "grade": false,
     "grade_id": "cell-a3504d53a9a04b33",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75a9493d8344227a0225dc62d3819c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corruption MSE: 0.06345630607604981\n",
      "Recovered MSE: 0.00898576021194458\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(load_model('./ebm/ebm_best.pth')[0])\n",
    "corruption_mse, mse, original, broken, recovered = evaluate(model, val_loader, n_sample_steps, step_lr, langevin_grad_norm, device=device)\n",
    "os.makedirs(f'./ebm/eval', exist_ok=True)\n",
    "\n",
    "torchvision.utils.save_image(\n",
    "                original, f\"./ebm/eval/groundtruth.png\", nrow=10)\n",
    "torchvision.utils.save_image(\n",
    "                broken, f\"./ebm/eval/corrupted.png\", nrow=10)\n",
    "torchvision.utils.save_image(\n",
    "                recovered, f\"./ebm/eval/recovered.png\", nrow=10)\n",
    "\n",
    "\n",
    "print(f'Corruption MSE: {corruption_mse}')\n",
    "print(f'Recovered MSE: {mse}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
