{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vit for classification in CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 25 10:41:05 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000004:04:00.0 Off |                    0 |\n",
      "| N/A   42C    P0              40W / 300W |      1MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "/nobackup/users/sqa24/anaconda3/envs/wgt/bin/python\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "!nvidia-smi\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from ViT.train import train\n",
    "    from ViT.utils import cifar_train_set, cifar_val_set\n",
    "    from ViT.model import *\n",
    "except:\n",
    "    from train import train\n",
    "    from utils import cifar_train_set, cifar_val_set\n",
    "    from model import *\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import datetime\n",
    "\n",
    "train_loader = DataLoader(cifar_train_set, 256, shuffle=True, drop_last=False, pin_memory=True)\n",
    "val_loader = DataLoader(cifar_val_set, 500, shuffle=True, drop_last=False, pin_memory=True)\n",
    "\n",
    "import os\n",
    "if not os.path.exists(\"ViT/log\"):\n",
    "    os.makedirs(\"ViT/log\")\n",
    "\n",
    "def timestr():\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "def get_outdir(time_str):\n",
    "    outdir = f\"ViT/log/{time_str}.out\"\n",
    "    return outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT(\n",
      "  (patch_embedding): Linear(in_features=48, out_features=256, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (transformer): Sequential(\n",
      "    (0): tranformer_layer(\n",
      "      (QKV): Linear(in_features=256, out_features=768, bias=True)\n",
      "      (fc): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (1): GELU()\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): tranformer_layer(\n",
      "      (QKV): Linear(in_features=256, out_features=768, bias=True)\n",
      "      (fc): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (1): GELU()\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): tranformer_layer(\n",
      "      (QKV): Linear(in_features=256, out_features=768, bias=True)\n",
      "      (fc): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (1): GELU()\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (3): tranformer_layer(\n",
      "      (QKV): Linear(in_features=256, out_features=768, bias=True)\n",
      "      (fc): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (1): GELU()\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (4): tranformer_layer(\n",
      "      (QKV): Linear(in_features=256, out_features=768, bias=True)\n",
      "      (fc): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (1): GELU()\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (5): tranformer_layer(\n",
      "      (QKV): Linear(in_features=256, out_features=768, bias=True)\n",
      "      (fc): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (1): GELU()\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (LN): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (to_cls_token): Identity()\n",
      "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "The model has 3,195,146 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:   0%|                                       | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 1.9702, Val Loss: 1.7904, Val Accuracy: 34.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50:   0%|                                       | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Train Loss: 1.6894, Val Loss: 1.5948, Val Accuracy: 41.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50:   0%|                                       | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Train Loss: 1.5796, Val Loss: 1.5294, Val Accuracy: 44.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50:   0%|                                       | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Train Loss: 1.5141, Val Loss: 1.5360, Val Accuracy: 45.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50:   0%|                                       | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Train Loss: 1.4673, Val Loss: 1.5013, Val Accuracy: 46.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50:   0%|                                       | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Train Loss: 1.4444, Val Loss: 1.4376, Val Accuracy: 48.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50:   0%|                                       | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Train Loss: 1.4211, Val Loss: 1.4136, Val Accuracy: 49.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50:   0%|                                       | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Train Loss: 1.3926, Val Loss: 1.3810, Val Accuracy: 50.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50:   0%|                                      | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Train Loss: 1.3671, Val Loss: 1.3539, Val Accuracy: 51.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50:   0%|                                      | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Train Loss: 1.3485, Val Loss: 1.3562, Val Accuracy: 51.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50:   0%|                                      | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Train Loss: 1.3398, Val Loss: 1.3275, Val Accuracy: 52.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50:   0%|                                      | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Train Loss: 1.3268, Val Loss: 1.3013, Val Accuracy: 53.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50:   0%|                                      | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Train Loss: 1.3118, Val Loss: 1.3450, Val Accuracy: 51.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50:   0%|                                      | 0/196 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Train Loss: 1.2965, Val Loss: 1.2867, Val Accuracy: 54.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50:  61%|██████▋    | 119/196 [00:24<00:15,  4.89it/s, Train Loss=1.29]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3070205/714865292.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m train(epochs=epochs, model=model, optimizer=optimizer, criterion=nn.CrossEntropyLoss(), \n\u001b[0;32m---> 21\u001b[0;31m       train_loader=train_loader, val_loader=val_loader)\n\u001b[0m",
      "\u001b[0;32m~/ViT/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, model, optimizer, criterion, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nobackup/users/sqa24/anaconda3/envs/wgt/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Here is the hyperparameters\n",
    "\n",
    "epochs = 50\n",
    "patch_size = 8\n",
    "embed_dim = 256\n",
    "n_layers = 6\n",
    "heads = 8\n",
    "attn_dim = 512\n",
    "mlp_dim = None # default to 4*embed_dim\n",
    "pool = 'cls'\n",
    "dropout = 0.0\n",
    "\n",
    "model = ViT(image_size=32, patch_size=patch_size, num_classes=10, embed_dim=embed_dim, n_layers=n_layers, heads=heads, attndim=attn_dim, mlp_dim=mlp_dim, pool=pool, dropout=dropout)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4, betas=(0.9, 0.999), weight_decay=5e-4)\n",
    "\n",
    "time_str = timestr()\n",
    "\n",
    "print(f\"Time string: {time_str}\")\n",
    "\n",
    "# print the model and the number of parameters\n",
    "# print(model.transformer)\n",
    "print(f'The model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} trainable parameters')\n",
    "\n",
    "train(epochs=epochs, model=model, optimizer=optimizer, criterion=nn.CrossEntropyLoss(), \n",
    "      train_loader=train_loader, val_loader=val_loader, outdir=get_outdir(time_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'ViT.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
