the modelViT(
  (patch_embedding): Linear(in_features=768, out_features=512, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
  (transformer): Sequential(
    (0): tranformer_layer(
      (QKV): Linear(in_features=512, out_features=3072, bias=False)
      (fc): Linear(in_features=1024, out_features=512, bias=False)
      (mlp): Sequential(
        (0): Linear(in_features=512, out_features=2048, bias=True)
        (1): GELU()
        (2): Dropout(p=0.2, inplace=False)
        (3): Linear(in_features=2048, out_features=512, bias=True)
      )
      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (dropout1): Dropout(p=0.2, inplace=False)
      (dropout2): Dropout(p=0.2, inplace=False)
    )
    (1): tranformer_layer(
      (QKV): Linear(in_features=512, out_features=3072, bias=False)
      (fc): Linear(in_features=1024, out_features=512, bias=False)
      (mlp): Sequential(
        (0): Linear(in_features=512, out_features=2048, bias=True)
        (1): GELU()
        (2): Dropout(p=0.2, inplace=False)
        (3): Linear(in_features=2048, out_features=512, bias=True)
      )
      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (dropout1): Dropout(p=0.2, inplace=False)
      (dropout2): Dropout(p=0.2, inplace=False)
    )
    (2): tranformer_layer(
      (QKV): Linear(in_features=512, out_features=3072, bias=False)
      (fc): Linear(in_features=1024, out_features=512, bias=False)
      (mlp): Sequential(
        (0): Linear(in_features=512, out_features=2048, bias=True)
        (1): GELU()
        (2): Dropout(p=0.2, inplace=False)
        (3): Linear(in_features=2048, out_features=512, bias=True)
      )
      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (dropout1): Dropout(p=0.2, inplace=False)
      (dropout2): Dropout(p=0.2, inplace=False)
    )
    (3): tranformer_layer(
      (QKV): Linear(in_features=512, out_features=3072, bias=False)
      (fc): Linear(in_features=1024, out_features=512, bias=False)
      (mlp): Sequential(
        (0): Linear(in_features=512, out_features=2048, bias=True)
        (1): GELU()
        (2): Dropout(p=0.2, inplace=False)
        (3): Linear(in_features=2048, out_features=512, bias=True)
      )
      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (dropout1): Dropout(p=0.2, inplace=False)
      (dropout2): Dropout(p=0.2, inplace=False)
    )
    (4): tranformer_layer(
      (QKV): Linear(in_features=512, out_features=3072, bias=False)
      (fc): Linear(in_features=1024, out_features=512, bias=False)
      (mlp): Sequential(
        (0): Linear(in_features=512, out_features=2048, bias=True)
        (1): GELU()
        (2): Dropout(p=0.2, inplace=False)
        (3): Linear(in_features=2048, out_features=512, bias=True)
      )
      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (dropout1): Dropout(p=0.2, inplace=False)
      (dropout2): Dropout(p=0.2, inplace=False)
    )
    (5): tranformer_layer(
      (QKV): Linear(in_features=512, out_features=3072, bias=False)
      (fc): Linear(in_features=1024, out_features=512, bias=False)
      (mlp): Sequential(
        (0): Linear(in_features=512, out_features=2048, bias=True)
        (1): GELU()
        (2): Dropout(p=0.2, inplace=False)
        (3): Linear(in_features=2048, out_features=512, bias=True)
      )
      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (dropout1): Dropout(p=0.2, inplace=False)
      (dropout2): Dropout(p=0.2, inplace=False)
    )
    (6): tranformer_layer(
      (QKV): Linear(in_features=512, out_features=3072, bias=False)
      (fc): Linear(in_features=1024, out_features=512, bias=False)
      (mlp): Sequential(
        (0): Linear(in_features=512, out_features=2048, bias=True)
        (1): GELU()
        (2): Dropout(p=0.2, inplace=False)
        (3): Linear(in_features=2048, out_features=512, bias=True)
      )
      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (dropout1): Dropout(p=0.2, inplace=False)
      (dropout2): Dropout(p=0.2, inplace=False)
    )
    (7): tranformer_layer(
      (QKV): Linear(in_features=512, out_features=3072, bias=False)
      (fc): Linear(in_features=1024, out_features=512, bias=False)
      (mlp): Sequential(
        (0): Linear(in_features=512, out_features=2048, bias=True)
        (1): GELU()
        (2): Dropout(p=0.2, inplace=False)
        (3): Linear(in_features=2048, out_features=512, bias=True)
      )
      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
      (dropout1): Dropout(p=0.2, inplace=False)
      (dropout2): Dropout(p=0.2, inplace=False)
    )
  )
  (LN): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (to_cls_token): Identity()
  (fc): Linear(in_features=512, out_features=10, bias=True)
)
the transformerSequential(
  (0): tranformer_layer(
    (QKV): Linear(in_features=512, out_features=3072, bias=False)
    (fc): Linear(in_features=1024, out_features=512, bias=False)
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=2048, bias=True)
      (1): GELU()
      (2): Dropout(p=0.2, inplace=False)
      (3): Linear(in_features=2048, out_features=512, bias=True)
    )
    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
  )
  (1): tranformer_layer(
    (QKV): Linear(in_features=512, out_features=3072, bias=False)
    (fc): Linear(in_features=1024, out_features=512, bias=False)
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=2048, bias=True)
      (1): GELU()
      (2): Dropout(p=0.2, inplace=False)
      (3): Linear(in_features=2048, out_features=512, bias=True)
    )
    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
  )
  (2): tranformer_layer(
    (QKV): Linear(in_features=512, out_features=3072, bias=False)
    (fc): Linear(in_features=1024, out_features=512, bias=False)
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=2048, bias=True)
      (1): GELU()
      (2): Dropout(p=0.2, inplace=False)
      (3): Linear(in_features=2048, out_features=512, bias=True)
    )
    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
  )
  (3): tranformer_layer(
    (QKV): Linear(in_features=512, out_features=3072, bias=False)
    (fc): Linear(in_features=1024, out_features=512, bias=False)
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=2048, bias=True)
      (1): GELU()
      (2): Dropout(p=0.2, inplace=False)
      (3): Linear(in_features=2048, out_features=512, bias=True)
    )
    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
  )
  (4): tranformer_layer(
    (QKV): Linear(in_features=512, out_features=3072, bias=False)
    (fc): Linear(in_features=1024, out_features=512, bias=False)
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=2048, bias=True)
      (1): GELU()
      (2): Dropout(p=0.2, inplace=False)
      (3): Linear(in_features=2048, out_features=512, bias=True)
    )
    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
  )
  (5): tranformer_layer(
    (QKV): Linear(in_features=512, out_features=3072, bias=False)
    (fc): Linear(in_features=1024, out_features=512, bias=False)
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=2048, bias=True)
      (1): GELU()
      (2): Dropout(p=0.2, inplace=False)
      (3): Linear(in_features=2048, out_features=512, bias=True)
    )
    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
  )
  (6): tranformer_layer(
    (QKV): Linear(in_features=512, out_features=3072, bias=False)
    (fc): Linear(in_features=1024, out_features=512, bias=False)
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=2048, bias=True)
      (1): GELU()
      (2): Dropout(p=0.2, inplace=False)
      (3): Linear(in_features=2048, out_features=512, bias=True)
    )
    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
  )
  (7): tranformer_layer(
    (QKV): Linear(in_features=512, out_features=3072, bias=False)
    (fc): Linear(in_features=1024, out_features=512, bias=False)
    (mlp): Sequential(
      (0): Linear(in_features=512, out_features=2048, bias=True)
      (1): GELU()
      (2): Dropout(p=0.2, inplace=False)
      (3): Linear(in_features=2048, out_features=512, bias=True)
    )
    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
    (dropout1): Dropout(p=0.2, inplace=False)
    (dropout2): Dropout(p=0.2, inplace=False)
  )
)
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 5e-05
    weight_decay: 0
)
Epoch 0: train loss 0.23044834050317162, val loss 0.8635651737451553, val accuracy 77.27, train acc 91.7425
Epoch 1: train loss 0.2030095595616502, val loss 0.8888314932584762, val accuracy 77.56, train acc 92.7
Epoch 2: train loss 0.1849334678187157, val loss 0.9265351936221122, val accuracy 76.76, train acc 93.485
Epoch 3: train loss 0.17526690104898934, val loss 0.9467528641223908, val accuracy 77.18, train acc 93.78
Epoch 4: train loss 0.16930878955049636, val loss 0.9634737715125083, val accuracy 76.96, train acc 93.9075
Epoch 5: train loss 0.16346052027167604, val loss 0.9893789857625961, val accuracy 76.71, train acc 94.1325
Epoch 6: train loss 0.15603064271969536, val loss 1.04627945125103, val accuracy 76.06, train acc 94.35
Epoch 7: train loss 0.1483707053545184, val loss 1.00248853713274, val accuracy 76.76, train acc 94.8375
Epoch 8: train loss 0.14461117174726323, val loss 1.0558999478816986, val accuracy 76.13, train acc 94.7875
Epoch 9: train loss 0.13983643870241344, val loss 1.0034263506531715, val accuracy 77.35, train acc 94.9675
Epoch 10: train loss 0.13324044037836427, val loss 1.0481283619999886, val accuracy 76.8, train acc 95.2625
Epoch 11: train loss 0.12952322487871107, val loss 1.0396207511425017, val accuracy 77.03, train acc 95.44
Epoch 12: train loss 0.1231544084680347, val loss 1.0774315863847732, val accuracy 76.31, train acc 95.5875
Epoch 13: train loss 0.12188586641471988, val loss 1.059136413037777, val accuracy 77.19, train acc 95.6475
Epoch 14: train loss 0.11769633456921806, val loss 1.0614080414175988, val accuracy 77.14, train acc 95.85
Epoch 15: train loss 0.10917493398673238, val loss 1.100760568678379, val accuracy 77.02, train acc 96.17
Epoch 16: train loss 0.11139423415636102, val loss 1.0830620735883714, val accuracy 76.32, train acc 96.0575
Epoch 17: train loss 0.10955605534509348, val loss 1.094540113210678, val accuracy 76.62, train acc 96.035
Epoch 18: train loss 0.10226613987748996, val loss 1.0978695198893547, val accuracy 77.42, train acc 96.3875
Epoch 19: train loss 0.09861441992056637, val loss 1.1246838465332984, val accuracy 76.57, train acc 96.49
Epoch 20: train loss 0.09669825393028153, val loss 1.1285646647214889, val accuracy 76.72, train acc 96.565
Epoch 21: train loss 0.09759236521090563, val loss 1.1444349199533463, val accuracy 76.82, train acc 96.58
Epoch 22: train loss 0.09152951449774706, val loss 1.1312062323093415, val accuracy 76.93, train acc 96.755
Epoch 23: train loss 0.08697906832773084, val loss 1.1010463252663611, val accuracy 77.77, train acc 96.8625
Epoch 24: train loss 0.08361094937133141, val loss 1.1630089670419692, val accuracy 77.01, train acc 97.0775
Epoch 25: train loss 0.08821127900538353, val loss 1.1435678094625472, val accuracy 77.03, train acc 96.8725
Epoch 26: train loss 0.08378258300498842, val loss 1.1235126554965973, val accuracy 77.63, train acc 97.0075
Epoch 27: train loss 0.0802826336659372, val loss 1.140803301334381, val accuracy 77.5, train acc 97.13
Epoch 28: train loss 0.07842221746024804, val loss 1.156877200305462, val accuracy 77.16, train acc 97.16
Epoch 29: train loss 0.07489007242476217, val loss 1.1851002007722855, val accuracy 77.03, train acc 97.3
Epoch 30: train loss 0.07274015276386334, val loss 1.1697350040078163, val accuracy 77.15, train acc 97.47
Epoch 31: train loss 0.07204362631034546, val loss 1.1835957616567612, val accuracy 77.43, train acc 97.4775
Epoch 32: train loss 0.07239035973414636, val loss 1.1628926038742065, val accuracy 77.66, train acc 97.48
Epoch 33: train loss 0.06892831026079556, val loss 1.1811966553330422, val accuracy 77.62, train acc 97.62
Epoch 34: train loss 0.06511868213336118, val loss 1.2200665190815925, val accuracy 77.53, train acc 97.7125
Epoch 35: train loss 0.06814708409551233, val loss 1.2354953080415725, val accuracy 76.78, train acc 97.7225
Epoch 36: train loss 0.06398523802431627, val loss 1.2123140096664429, val accuracy 77.41, train acc 97.73
Epoch 37: train loss 0.05760594542486409, val loss 1.2848696410655975, val accuracy 76.73, train acc 97.9625
Epoch 38: train loss 0.06047427372786755, val loss 1.2912814736366272, val accuracy 77.0, train acc 97.855
Epoch 39: train loss 0.0586676857710932, val loss 1.2607970386743546, val accuracy 77.04, train acc 97.9525
Epoch 40: train loss 0.06032132615629857, val loss 1.240357418358326, val accuracy 77.01, train acc 97.9475
Epoch 41: train loss 0.0549107105813373, val loss 1.305225445330143, val accuracy 76.89, train acc 98.16
Epoch 42: train loss 0.05483683267721353, val loss 1.240083721280098, val accuracy 77.5, train acc 98.0675
Epoch 43: train loss 0.05275208357209786, val loss 1.3078856870532036, val accuracy 77.49, train acc 98.2325
Epoch 44: train loss 0.0510239491459375, val loss 1.3540521621704102, val accuracy 76.37, train acc 98.2025
Epoch 45: train loss 0.049531437581577624, val loss 1.3248904779553414, val accuracy 77.02, train acc 98.28
Epoch 46: train loss 0.05478731997477742, val loss 1.2692296102643013, val accuracy 77.58, train acc 98.085
Epoch 47: train loss 0.05371453038181741, val loss 1.324403640627861, val accuracy 77.07, train acc 98.1475
Epoch 48: train loss 0.04666097671650469, val loss 1.3082860291004181, val accuracy 77.23, train acc 98.41
Epoch 49: train loss 0.05316893756984712, val loss 1.2926184251904487, val accuracy 77.6, train acc 98.1875
